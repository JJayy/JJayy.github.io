---
layout: post
title: Day8
hide_title: False
excerpt: Boost Camp AI Tech - DAY 8
toc: true
toc_sticky: true
# toc_label: Category
feature-img: assets/img/feature-img/story.jpeg
author: Jay
tags: [Boost camp, AI tech, Day8]
---

# Day 7

#### 진행 사항
  - [x] pandas 1
  - [x] Mathematics for Artificial Intelligence
    - [x] 5강: 딥러닝 학습방법 이해하기
  - [x] 피어세션 
  - [x] 개인학습


## 학습 내용
---
금  

다음은 강의 내용을 정리한 것입니다.   

<br> 

## Pandas 1
---

### pandas
panel data의 줄임말로 구조화된 데이터의 처리를 지원하는 Python 라이브러리입니다. 고성능 array 계산 라이브러리인 numpy의 기능들을 지원하면서 강력한 '스프레드시트'처리 기능을 제공합니다. 인덱싱, 연산용 함수, 전처리 함수 등을 제공합니다. 파이썬계의 엑셀이라고 생각할 수 있으며, 테이블 형태 데이터를 다루는데에 특화되어 있어 데이터 처리 및 통계 분석을 위해 사용합니다.   
~~~python
import pandas as pd

data_url = 'csv파일 주소'
df_data = pd.read_csv(data_url, sep='\s+', header = None)  # csv 타입 데이터 로드, seperate는 빈공간(스페이스)로 지정하고 column은 없음
df_data.head()  # 데이터의 첫 5줄 출력 (default가 5줄)

df_data.columns = ['이름', '생년월일', '나이']  # column header 이름 지정
~~~

#### Series & dataframe
pandas 자료의 구성은 데이터 테이블 전제를 포함하는 오브젝트인 dataframe과 각 column에 해당하는 데이터의 모음 object인 series가 있습니다. 즉, dataframe은 series의 모음이기도 합니다.      
일반적으로는 데이터를 불러와서 쓰기 때문에 dataframe을 따로 생성할 일은 없으나 직접 데이터를 가지고 데이터 테이블을 만들기 위해서는 dataframe 함수를 적용해야 합니다.   

**Series**   
시리즈 함수는 다음 인자를 바탕으로 생성됩니다.   
> Series(data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)

먼저 Series를 생성하는 방법에 대해 알아보겠습니다.   

~~~python
from pandas import Series
import pandas as pd
import numpy as np

list_data = [1,2,3]
example_obj = Series(data=list_data)
example_obj
>>> 0  1
>>> 1  2
>>> 2  3
>>> dtype: int64

index_data_1 = ['a', 'b', 'c', 'd']
index_data_2 = ['e', 'f']
example_obj_2 = Series(data=list_data, index = index_data_1)
example_obj_2
>>> a  1
>>> b  2
>>> c  3
>>> d  NaN   # index 기준으로 column 생성
>>> dtype: int64

example_obj_3 = Series(data=list_data, index = index_data_2)
>>> e  1
>>> f  2  # index 기준으로  column 생성
>>> dtype: int64


example_obj_3.index   # 인덱스 리스트
>>> Index(['e', 'f'], dtype='object')
example_obj_3.values
>>> array([1, 2])   # 값 리스트
type(example_obj_3.values)
>>> numpy.ndarray


dict_data = {"a":1, "c": 2, "e": 3}
example_obj_4 = Series(dict_data, dtype=np.float32, name="example_data")
example_obj_4
>>> a  1.0
>>> c  2.0
>>> e  3.0
>>> Name: example_data, dtype: float32
~~~

다음으로는 Series를 다루는 방법에 대해 알아보겠습니다.   

~~~python
dict_data = {"a":1, "c": 2, "e": 3}
example_obj = Series(dict_data, dtype=np.float32, name="example_data")

example_obj["a"] # 인덱스를 통해 값 불러오기
>>> 1.0
example_obj["a"] = 4.0 # 값 바꾸기
example_obj
>>> a  4.0
>>> c  2.0
>>> e  3.0
>>> Name: example_data, dtype: float32

example_obj = example_object.astype(int) # 데이터 타입 바꾸기
example_obj
>>> a  4
>>> c  2
>>> e  3
>>> Name: example_data, dtype: int64

example_obj.name = "number"  # Series 이름 지정
example_obj.index.name = "alphabet"  # index 열의 이름 지정
~~~


**Dataframe**   
Series들이 모여 만들어진 것이 dataframe입니다. 때문에 기본적으로 2차원 행렬이게 됩니다. dataframe 함수의 인자는 다음과 같습니다.   
> DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)

~~~python
from pandas import Series, DataFrame
import pandas as pd
import numpy as np

raw_data = {'first name':['Jason','Amy'], 'last name':['Miler', 'Ali'], 'age':[42, 24]}
df = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age'])  # raw_data의 모든 값 불러오기
                            # columns 에서 가져오고 싶은 값만 선택하거나 아예 새로운 값을 넣어 열(column)을 추가할 수 있음
                            # 이때 값은 NaN으로 채워지게 됨
df.first_name  # column 이름이 first_name인 series를 추출
df["first_name"]  # column 이름이 first_name인 series를 추출
df[df.age > 30]  # 조건을 만족하는 행만 추출

df.age > 30
>>> array([True, False])
df["age_over_30"] = df.age > 30  #새로운 column 'age_over_30'이 생기고 조건에 따른 True, False 값이 채워집니다. 

del df["age_over_30"]  # 열을 데이터 테이블에서 완전히 삭제합니다. 
df.drop("age_over_30", axis=1, inplace=False) # 열을 데이터 테이블에서 삭제한 값을 반환합니다. 기존 데이터 테이블은 유지됩니다. inplace를 True로 하면 df 자체에서 삭제됩니다.
df.drop([0, 1]) #row index 값을 넣어 행을 삭제할 수 있습니다.
~~~

index를 통해 데이터를 처리하는 방법에는 loc과 iloc이 있습니다. loc은 index의 이름으로 호출하며, iloc은 index의 번호로 호출합니다.   
~~~python
s = pd.Series(np.nan, index=[11, 13, 0, 2, 1])
s.loc[:2]   #2차원 행렬인 dataframe에서는 순서대로 column(row name), row(Column name)입니다. 
            #df.loc[[11, 13, 0], ["first_name", "age"]] 둘다 이름으로 호출합니다.
            #df[["first_name", "age"]][:2]  --> first name과 age column의 index 이름이 2인 행까지 출력
            #기존호출은 반대입니다. 
>>> 11  NaN
>>> 13  NaN
>>> 0   NaN
>>> 2   NaN

s.iloc[:2]  # loc과 마찬가지로 2차원 행렬인 dataframe에서는 column(row number), row(column number) 순서를 가집니다.
            # df.iloc[:2, :2]  순서대로 0-1행과 0-1열을 출력
>>> 11  NaN
>>> 13  NaN
~~~

#### dataframe operations
**series operations**   
series간에 연산이 가능한데 모든 연산은 index 기준으로 이루어집니다. index의 이름이 같을 경우 연산을 진행하고 이름이 없다면 index number로 맞추어 연산합니다. 하지만 두 series 중 하나의 series에 index가 존재하지 않는다면 연산값은 NaN으로 채워집니다. 이를 방지하기 위해서 fill_value라는 값을 사용하게 됩니다.   

~~~python
df1 = DataFrame(np.arange(9).reshape(3,3), columns=list("abc"))
df2 = DataFrame(np.arrange(16).reshape(4,4), columns=list("abcd"))
df+df2 # 행과 열 모두 df1에 해당하는 0-2까지는 계산이 되지만 df2의 3행이나 3열은 df1에 없기 때문에 NaN이 채워집니다. 

df1.add(df2, fill_value=0) # df2에는 있지만 df1에는 없는 값이 0으로 채워져 연산이 진행되어 모든 값이 표시됩니다. 
df1.mul(df2, fill_value=1) # 곱셈은 1을 넣어 값을 표시할 수 있습니다. (add, sub, div, mul 사용 가능)
~~~


#### lambda, map, apply
series type 데이터에도 map 함수가 사용 가능합니다. function 대신 dict, sequence형 자료 등으로 대체 가능합니다.   
~~~python
s1 = Series(np.arange(10))
s1.map(lambda x: x**2)
s1.head()
>>> 0  0
>>> 1  1
>>> 2  4
>>> 3  9
>>> 4 16
>>> dtype: int64

s2 = Series(np.arange(10,20))
s1.map(s2) # 같은 index의 s2 데이터를 s1에 mapping
s1.head()
>>> 0  10
>>> 1  11
>>> 2  12
>>> 3  13
>>> 4  14
~~~

직접 변환하고자 하는 데이터는 replace() 함수를 사용하여 변환 가능합니다. 역시 inplace를 True로 사용하면 데이터 테이블 자체가 변화합니다.   

> df.시리즈이름.replace(['값1', '값2'], [0, 1], inplace=False) 
> \>시리즈 이름에 해당하는 column 내의 값1을 0으로 값2를 1로 변환

이 외에도 각각의 값에 mapping을 시키던 map함수와 달리 column 전체의 데이터를 입력으로 받아 함수를 계산하는 경우 apply() 함수를 적용할 수 있습니다. 예시로는 column 내 최대값과 최소값의 차를 구하는 것을 들 수 있습니다.   
~~~python
f = lambda x: x.max()-x.min()
df.apply(f)
~~~
때문에 내장 연산 함수를 사용하는 것과 같은 결과값을 얻을 수 있습니다. 
> df.sum() #모든 값의 합
> df.apply(sum) #모든 column 값을 합하는 식을 적용

applymap()을 사용하면 series 단위가 아닌 element 단위로 함수를 적용할 수 있습니다.   


#### pandas built-in functions
**describe**   
> df.describe()

Numeric type 데이터의 요약 정보를 보여줍니다.   
count, mean, std, min, 25%, 50%, 75%, max 등의 값을 연산하여 제공합니다.   


**unique**   
series data의 유일한 값을 list로 반환합니다.    
이를 활용하여 dict type으로 index를 매겨 반환받거나 label index와 label 값을 각각 추출할 수도 있습니다.   

**isnull**   
NaN(null) 값의 index를 반환합니다. sum()과 같은 함수로 Null인 값의 합을 구할수도 있습니다.   

**sort_values**   
column 값을 기준으로 데이터를 정렬합니다.   
> df.sort_values(["column1", "column2"], ascending=True)

**Correlation & Covariance**   
상관계수와 공분산을 구하는 함수로, corr(), cov(), corrwith()가 있습니다. 
> df.age.corr(df.earn)
> df.age.cov(df.earn)  #age column과 earn column 사이의 covariance를 계산합니다. 


<br>

## Mathematics for Artificial Intelligence
---   
**딥러닝 학습 방법 이해하기**    

앞서 데이터를 선형모델로 해석하여 목적식인 y를 구하기 위해 y와 가장 근사하는 y^(y hat)을 만들어주는 beta 값을 경사하강법을 통해 학습하는 내용에 대해 배웠습니다. 복잡한 패턴을 가진 모델의 경우 선형모델만드로는 예측이 어렵게 됩니다. 때문에 신경망을 모델에 고려하게 되는데 이와 같은 신경망은 비선형모델입니다. 그러나 신경망 내부를 들여다보면 선형모델과 비선형모델의 결합으로 이루어져 있음을 알 수 있습니다. 신경망을 수식으로 분해하여 선형모델을 기반으로 비선형모델의 패턴을 학습할 수 있는지에 대해 알아보겠습니다.   

### 신경망(neural network)
신경망은 선형 모델과 비선형 모델인 활성함수(activation fuction)를 합성한 함수입니다. 이와 같은 신경망이 여러층 합성 된 함수를 다층(multi-layer) 퍼셉트론(MLP)이라고 부릅니다. 일반적으로 층이 깊을수록 목적함수를 근사하는데 필요한 뉴런(노드)의 숫자가 훨씬 빨리 줄어들기 때문에 효율적으로 학습이 가능합니다.    

#### 선형 모델
우리가 가진 데이터 셋 행렬을 X(n x d), 가중치 행렬을 W(d x p) 그리고 절편 벡터 b(n x p)라고 할때 출력값인 행벡터는 O(n x p)로 표현할 수 있습니다.   

> O = X * W + b

이때 가중치(weight)의 차원(p)에 따라 기존 차원(d)에서 p로 바뀌게 됩니다. 즉, d개의 변수로 p개의 선형모델을 만들어서 p개의 잠재변수를 설명하는 모델을 상상해 볼 수 있습니다. 

#### 활성함수
활성함수에 대해 이야기하기 전에 softmax 함수에 대해 알아보겠습니다.   

**softmax()**   
softmax는 앞서 구한 선형 모델의 출력 벡터를 합성하여 특정 클래스 k에 속할 확률벡터를 만들어 주는 역할을 합니다. 때문에 분류 문제를 풀 때 선형모델과 softmax() 함수를 결합하여 예측합니다.   
> softmax(O) = softmax(Wx+b)

~~~python
def softmax(vec):
    denumerator = np.exp(vec - np.max(vec, axis=-1, keepdims=True))
    numerator = np.sum(denumerator, axis=-1, keepdims=True)
    val = denumerator/numerator
    return val

vec = np.array([[1,2,0],[-1,0,1],[-10,0,10]])
softmax(vec)
>>> array([[2.44728471e-01, 6.65240956e-01, 9.00305732e-02],
           [9.00305732e-02, 2.44728571e-01, 6.65240956e-01],
           [2.06106005e-09, 4.53978686e-05, 9.99954500e-01]])
~~~
확률에 대한 학습을 진행할 떄는 softmax() 함수를 이용하지만, 결과값을 추론할 때는 one-hot 벡터로 최대값을 가진 주소만 1을 출력하는 연산을 softmax()를 사용하지 않고 직접 출력 벡터에 적용합니다.   
~~~python
def on_hot(val, dim):
    return [np.eye(dim)[_] for _ in val]

def one_hot_encoding(vvec):
    vec_dim = vec.shape[1]
    vec_argmax = np.argmax(vec, axis=-1)
    return one_hot(vec_argmax, vec_dim)

def softmax(vec):
    denumerator = np.exp(vec - np.max(vec, axis=-1, keepdims=True))
    numerator = np.sum(denumerator, axis=-1, keepdims=True)
    val = denumerator/numerator
    return val

vec = np.array([[1,2,0],[-1,0,1],[-10,0,10]])
one_hot_encoding(vec)
>>> array([[0.,1.,0.], [0.,0.,1.],[0.,0.,1.]])
one_hot_encoding(softmax(vec))
>>> array([[0.,1.,0.], [0.,0.,1.],[0.,0.,1.]]) #softmax한 값도 같은 값을 가지므로 굳이 softmax를 연산할 필요가 없다.
~~~

**활성 함수**   
앞서 이야기한 softmax의 활성함수 트릭을 이용하여 선형모델을 활성함수를 통해 비선형함수로 만들 수 있습니다. 활성함수 자체는 비선형 함수로 앞서 선형 모델의 출력벡터(잠재벡터)의 각 노드에 개별적으로 계산을 진행하여 새로운 잠재벡터(H)를 만듭니다. softmax()와의 차이점이라면 softmax는 전체 데이터와 한꺼번에 결합하여 계산하지만, 활성함수는 각 노드에 개별적으로 적용된다는 차이점이 있습니다. (활성함수는 소문자 시그마 기호를 씁니다.)   

> 잠재벡터(z) = Wx + b
> H = sigma(z) = (sigma(z1), sigma(z2), ... , sigma(zn)) = sigma(Wx+b)

활성함수는 비선형(nonlinear)함수로 이를 적용하지 않으면 딥러닝은 선형모양과 차이점이 없게 됩니다. 시그모이드(sigmoid) 함수나 tanh 함수가 전통적으로 많이 쓰이지만 딥러닝에서는 ReLU 함수를 많이 쓰고 있습니다.   

> ReLu(x) = max{0, x}

#### 다층 신경망
선형 모델의 잠재벡터(z)에 활성함수를 적용하여 얻은 잠재벡터(H)에 다시 가중치 행렬(W2)와 절편 벡터(beta2)를 통해 다시 선형 변환을 진행할 수 있으며, 이렇게 구성한 신경망을 W2, W1을 패러미터로 가진 2층(2-layers) 신경망이라고 합니다.   

2개 이상의 층을 가진 신경망을 다층 신경망이라고 부르며, 수식으로 나타낼 때 L개의 가중치 행렬로 이루어져 있다고 표현합니다.   
> O = Z_l
> ...
> H_l = sigma(Z_l)
> Z_l = H_l-1 *W_l + beta_l
> ...
> H_1 = sigma(Z_1)
> Z_1 = XW_1 + beta_1

이렇게 다층 신경망을 이용하는 이유는 이론적으로 2개 이상의 층을 가지게 되면 임의의 연속함수를 근사할 수 있기 때문입니다. 이를 universal approximation theorem이라고 합니다. 층이 깊을수록(많을수록) 선형 변환에 의해 d차원에서 p 차원으로 (d>p) 변화하기 때문에 필요한 뉴런(노드)의 숫자가 훨씬 빨리 줄어들어 조금 더 효율적인 학습이 가능합니다.    

#### 역전파 알고리즘
지금까지 신경망을 구성하는 과정은 순서대로 진행되는 forwardpropagation이라고 합니다. 하지만 여기서 우리는 가중치 행렬(W)에 대해 학습하는 것이 목적이기 때문에 이 과정을 꺼꾸로 진행하는 역전파(backpropagation) 알고리즘을 이용하여 각 층에 사용된 패러미터 W와 beta를 학습합니다.   

각 층의 패러미터의 그레디언트 벡터는 윗층부터 역순으로 계산하게 됩니다. 이 과정에서 L부터 1의 순서로 연쇄법칙을 통해 그레디어트 벡터를 전달합니다.   
> dL/dW_l = dL/dO  x  ...  x dZ_l/dW_l
> dL/dbeta_l = dL/dO x ... x dZ_l/dbeta_l



<br>

## 피어세션
---
dacon 참여 논의

softmax one hat

max 빼는 이유

비선형 이유(선형으로 풀 수 없는 XOR 문제)

span

<br>

## 개인 학습
---
앞서